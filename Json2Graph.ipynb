{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper maps/dictionaries\n",
    "\n",
    "# Map from string to its numerical weight\n",
    "edge_weight_map = { '++': 2, '+': 1, '0': 0, '-': -1, '--': -2 }\n",
    "\n",
    "# Data type of edge in graph\n",
    "dt_edge = [('weight', int),\n",
    "           ('weight_absolute', int), \n",
    "           ('strengthen', int), \n",
    "           ('weaken', int), \n",
    "           ('sign', int)]\n",
    "\n",
    "# Maps string to dt_edge quintuple\n",
    "def edge_map(w):\n",
    "    w = edge_weight_map[w]\n",
    "    abs_w = abs(w)\n",
    "    sign = np.sign(w)\n",
    "    return (w, abs_w, (abs_w if sign == 1 else 0), (abs_w if sign == -1 else 0), sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts action systems from loaded data\n",
    "def get_action_systems(data):\n",
    "    entries = {}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        entries[entry['id']] = entry['name']\n",
    "    \n",
    "    return entries\n",
    "\n",
    "def get_life_entries(data, action_systems):\n",
    "    identifier = {}\n",
    "    labels = {}\n",
    "    node_action_systems_id = {}\n",
    "    node_action_systems = {}\n",
    "    influences = {}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        identifier[i] = entry['id']\n",
    "        labels[i] = entry['title']\n",
    "        node_action_systems_id[i] = entry['actionSystemId']\n",
    "        node_action_systems[i] = action_systems[entry['actionSystemId']]\n",
    "        influences[i] = entry['influence']\n",
    "    \n",
    "    return identifier, labels, node_action_systems_id, node_action_systems, influences\n",
    "\n",
    "# Loads the json and creates a networkx multidi graph\n",
    "def json_to_graph(path, encoding='utf-8', verbose=False):\n",
    "    json_data = None\n",
    "    action_systems = {}\n",
    "    labels = {}\n",
    "    node_action_systems = {}\n",
    "    influences = {}\n",
    "    \n",
    "    with open(path, encoding=encoding) as data_file:\n",
    "        json_data = json.load(data_file)\n",
    "    \n",
    "    # Print the loaded json data\n",
    "    if verbose == True:\n",
    "        ppriint(json_data)\n",
    "    \n",
    "    # Gets adjacency matrix and maps it to the dt_edge data type\n",
    "    df = pd.DataFrame(json_data['connections'])\n",
    "    df = df.applymap(edge_map)\n",
    "    am = np.array(df, dtype=dt_edge)\n",
    "    \n",
    "    if verbose == True:\n",
    "        # Print mapped adjacency matrix\n",
    "        print(am)\n",
    "    \n",
    "    # Get action systems\n",
    "    action_systems = get_action_systems(json_data['actionSystems'])\n",
    "    \n",
    "    # Get life entries\n",
    "    identifier, labels, node_action_systems_id, node_action_systems, influences = get_life_entries(json_data['lifeEntries'], action_systems)\n",
    "    \n",
    "    # Create graph by loading the adjacency matrix\n",
    "    G = nx.from_numpy_matrix(am, parallel_edges=False, create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    # Set attributes on nodes\n",
    "    nx.set_node_attributes(G, identifier, name='id')\n",
    "    nx.set_node_attributes(G, labels, name='label')\n",
    "    nx.set_node_attributes(G, node_action_systems_id, name='actionSystemId')\n",
    "    nx.set_node_attributes(G, node_action_systems, name='actionSystem')\n",
    "    nx.set_node_attributes(G, influences, name='influence')\n",
    "    \n",
    "    return G\n",
    "\n",
    "def to_d3_json(G):\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    labels = nx.get_node_attributes(G, name='label')\n",
    "    influences = nx.get_node_attributes(G, name='influence')\n",
    "    action_systems = nx.get_node_attributes(G, name='actionSystem')\n",
    "    \n",
    "    weights = nx.get_edge_attributes(G, name='weight')\n",
    "    weight_absolute = nx.get_edge_attributes(G, name='weight_absolute')\n",
    "    strengthen = nx.get_edge_attributes(G, name='strengthen')\n",
    "    weaken = nx.get_edge_attributes(G, name='weaken')\n",
    "    sign = nx.get_edge_attributes(G, name='sign')\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        nodes.append({\n",
    "            'label': labels[i],\n",
    "            'influence': influences[i],\n",
    "            'actionSystem': action_systems[i]\n",
    "        })\n",
    "    \n",
    "    print(weights)\n",
    "    print(strengthen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric(G, name, func, weights=[]):\n",
    "    metric_data = {}\n",
    "    if len(weights) == 0:\n",
    "        # Metric is unweighted\n",
    "        metric_data[name] = func(G)\n",
    "    else:\n",
    "        # Metric is weighted, go though every weight attribute\n",
    "        for i, weight in enumerate(weights):\n",
    "            metric_data['{}_{}'.format(name, weight)] = func(G, weight=weight)\n",
    "            \n",
    "    return metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_metric(G, weights):\n",
    "    metric_data = {}\n",
    "    temp_data = {}\n",
    "    for i, weight in enumerate(weights):\n",
    "        temp_data['degree_{}'.format(weight)] = G.degree(weight=weight)\n",
    "        temp_data['in_degree_{}'.format(weight)] = G.in_degree(weight=weight)\n",
    "        temp_data['out_degree_{}'.format(weight)] = G.out_degree(weight=weight)\n",
    "    \n",
    "    temp_data['degree'] = G.degree()\n",
    "    temp_data['in_degree'] = G.in_degree()\n",
    "    temp_data['out_degree'] = G.out_degree()\n",
    "    \n",
    "    for i, metric in enumerate(temp_data):\n",
    "        metric_data[metric] = {}\n",
    "        for j, (node_id, value) in enumerate(temp_data[metric]):\n",
    "            metric_data[metric][node_id] = value\n",
    "    \n",
    "    return metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_json(G):\n",
    "\n",
    "    json_object = {}\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    # If a key does not exist on access, generate empty list\n",
    "    # So every node gets a 'cycle' attribute, even if it's just an empty list\n",
    "    cycles = defaultdict(list)\n",
    "    \n",
    "    # Get attributes from nodes (generated by JSON importer)\n",
    "    identifier = nx.get_node_attributes(G, name='id')\n",
    "    labels = nx.get_node_attributes(G, name='label')\n",
    "    action_systems_id = nx.get_node_attributes(G, name='actionSystemId')\n",
    "    action_systems = nx.get_node_attributes(G, name='actionSystem')\n",
    "    influences = nx.get_node_attributes(G, name='influence')\n",
    "    \n",
    "    # Get all possible directed graph metrics and add them to 'node_metrics' dict\n",
    "    node_metrics = {}\n",
    "    degree_metrics = rebuild_metric(G, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(degree_metrics)\n",
    "    degree_centrality = generate_metric(G, 'degree_centrality', nx.degree_centrality)\n",
    "    node_metrics.update(degree_centrality)\n",
    "    in_degree_centrality = generate_metric(G, 'in_degree_centrality', nx.in_degree_centrality)\n",
    "    node_metrics.update(in_degree_centrality)\n",
    "    out_degree_centrality = generate_metric(G, 'out_degree_centrality', nx.out_degree_centrality)\n",
    "    node_metrics.update(out_degree_centrality)\n",
    "    eigenvector_centrality_numpy = generate_metric(G, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy)\n",
    "    node_metrics.update(eigenvector_centrality_numpy)\n",
    "    eigenvector_centrality_numpy_weighted = generate_metric(G, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(eigenvector_centrality_numpy_weighted)\n",
    "    closeness_centrality = generate_metric(G, 'closeness_centrality', nx.degree_centrality)\n",
    "    node_metrics.update(closeness_centrality)\n",
    "    betweenness_centrality = generate_metric(G, 'betweenness_centrality', nx.betweenness_centrality)\n",
    "    node_metrics.update(betweenness_centrality)\n",
    "    betweenness_centrality_weighted = generate_metric(G, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(betweenness_centrality_weighted)\n",
    "    load_centrality = generate_metric(G, 'load_centrality', nx.load_centrality)\n",
    "    node_metrics.update(load_centrality)\n",
    "    load_centrality_weighted = generate_metric(G, 'load_centralityload_centrality', nx.load_centrality, ['weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(load_centrality_weighted)\n",
    "    harmonic_centrality = generate_metric(G, 'harmonic_centrality', nx.harmonic_centrality)\n",
    "    node_metrics.update(harmonic_centrality)\n",
    "    betweenness_centrality_weighted = generate_metric(G, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(betweenness_centrality_weighted)\n",
    "    \n",
    "    # Find cycles and build a 'cycle id' list\n",
    "    # Nodes with the same 'cycle id' belong to the same cycle\n",
    "    for i, cycle in enumerate(list(nx.simple_cycles(G))):\n",
    "        for j, node in enumerate(cycle):\n",
    "            cycles[node].append(i)\n",
    "            \n",
    "    # Generate sorted int list of 'cycle id'\n",
    "    cycles_list = [int(i) for i in sorted(list(cycles.keys()))]\n",
    "    \n",
    "    # Fill 'nodes' dict\n",
    "    for i in range(len(identifier)):\n",
    "        attributes = {\n",
    "            'id': identifier[i],\n",
    "            'label': labels[i],\n",
    "            'influence': influences[i],\n",
    "            'actionSystemId': action_systems_id[i],\n",
    "            'actionSystem': action_systems[i],\n",
    "            'cycles': cycles[i]\n",
    "        }\n",
    "        \n",
    "        for k, metric in enumerate(node_metrics):\n",
    "            attributes[metric] = node_metrics[metric][i]\n",
    "        \n",
    "        nodes.append(attributes)\n",
    "\n",
    "    # Get attributes from edges (generated by JSON importer)\n",
    "    weight_absolute = nx.get_edge_attributes(G, name='weight_absolute')\n",
    "    strengthen = nx.get_edge_attributes(G, name='strengthen')\n",
    "    weaken = nx.get_edge_attributes(G, name='weaken')\n",
    "    sign = nx.get_edge_attributes(G, name='sign')\n",
    "    \n",
    "    # Get all possible directed graph metrics and add them to 'edge_metrics' dict\n",
    "    edge_metrics = {}\n",
    "    edge_betweenness_centrality = generate_metric(G, 'edge_betweenness_centrality', nx.edge_betweenness_centrality)\n",
    "    edge_metrics.update(edge_betweenness_centrality)\n",
    "    edge_betweenness_centrality_weighted = generate_metric(G, 'edge_betweenness_centrality', nx.edge_betweenness_centrality, weights=['weight','weight_absolute','strengthen','weaken'])\n",
    "    edge_metrics.update(edge_betweenness_centrality_weighted)\n",
    "    edge_load_centrality = generate_metric(G, 'edge_load_centrality', nx.edge_load_centrality)\n",
    "    edge_metrics.update(edge_load_centrality)\n",
    "    \n",
    "    # Fill 'links' dict\n",
    "    for (from_node, to_node, weight) in G.edges(data='weight'):\n",
    "        attributes = {\n",
    "            'source': nodes[from_node]['id'],\n",
    "            'target': nodes[to_node]['id'],\n",
    "            'weight': weight,\n",
    "            'weight_absolute': weight_absolute[(from_node, to_node, 0)],\n",
    "            'strengthen': strengthen[(from_node, to_node, 0)],\n",
    "            'weaken': weaken[(from_node, to_node, 0)],\n",
    "            'sign': sign[(from_node, to_node, 0)]\n",
    "        }\n",
    "        \n",
    "        for k, metric in enumerate(edge_metrics):\n",
    "            attributes[metric] = edge_metrics[metric][(from_node, to_node)]\n",
    "            \n",
    "        links.append(attributes)\n",
    "    \n",
    "    json_object['cycles'] = cycles_list\n",
    "    json_object['nodes'] = nodes\n",
    "    json_object['links'] = links\n",
    "    \n",
    "    return json.JSONEncoder(ensure_ascii=False, allow_nan=False).encode(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_json_file(G, filename):\n",
    "    file = codecs.open(filename, \"w\", \"utf-8-sig\")\n",
    "    file.write(graph_to_json(G))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = json_to_graph('data/dataset_20180403/180331_Herbert_Heim.json')\n",
    "to_d3_json(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
