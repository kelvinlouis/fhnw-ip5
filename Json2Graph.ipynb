{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import codecs\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from ipywidgets import Layout\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper maps/dictionaries\n",
    "\n",
    "# Map from string to its numerical weight\n",
    "edge_weight_map = { '++': 2, '+': 1, '0': 0, '-': -1, '--': -2 }\n",
    "\n",
    "# Data type of edge in graph\n",
    "dt_edge = [('weight', int),\n",
    "           ('weight_absolute', int), \n",
    "           ('strengthen', int), \n",
    "           ('weaken', int), \n",
    "           ('sign', int)]\n",
    "\n",
    "# Maps string to dt_edge quintuple\n",
    "def edge_map(w):\n",
    "    w = edge_weight_map[w]\n",
    "    abs_w = abs(w)\n",
    "    sign = np.sign(w)\n",
    "    return (w, abs_w, (abs_w if sign == 1 else 0), (abs_w if sign == -1 else 0), sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts action systems from loaded data\n",
    "def get_action_systems(data):\n",
    "    entries = {}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        entries[entry['id']] = entry['name']\n",
    "    \n",
    "    return entries\n",
    "\n",
    "def get_life_entries(data, action_systems):\n",
    "    identifier = {}\n",
    "    labels = {}\n",
    "    node_action_systems_id = {}\n",
    "    node_action_systems = {}\n",
    "    influences = {}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        identifier[i] = entry['id']\n",
    "        labels[i] = entry['title']\n",
    "        node_action_systems_id[i] = entry['actionSystemId']\n",
    "        node_action_systems[i] = action_systems[entry['actionSystemId']]\n",
    "        influences[i] = entry['influence']\n",
    "    \n",
    "    return identifier, labels, node_action_systems_id, node_action_systems, influences\n",
    "\n",
    "# Loads the json and creates a networkx multidi graph\n",
    "def json_to_graph(path, encoding='utf-8', verbose=False):\n",
    "    json_data = None\n",
    "    action_systems = {}\n",
    "    labels = {}\n",
    "    node_action_systems = {}\n",
    "    influences = {}\n",
    "    \n",
    "    with open(path, encoding=encoding) as data_file:\n",
    "        json_data = json.load(data_file)\n",
    "    \n",
    "    # Print the loaded json data\n",
    "    if verbose == True:\n",
    "        ppriint(json_data)\n",
    "    \n",
    "    # Gets adjacency matrix and maps it to the dt_edge data type\n",
    "    df = pd.DataFrame(json_data['connections'])\n",
    "    df = df.applymap(edge_map)\n",
    "    am = np.array(df, dtype=dt_edge)\n",
    "    \n",
    "    if verbose == True:\n",
    "        # Print mapped adjacency matrix\n",
    "        print(am)\n",
    "    \n",
    "    # Get action systems\n",
    "    action_systems = get_action_systems(json_data['actionSystems'])\n",
    "    \n",
    "    # Get life entries\n",
    "    identifier, labels, node_action_systems_id, node_action_systems, influences = get_life_entries(json_data['lifeEntries'], action_systems)\n",
    "    \n",
    "    # Create graph by loading the adjacency matrix\n",
    "    G = nx.from_numpy_matrix(am, parallel_edges=False, create_using=nx.MultiDiGraph())\n",
    "    \n",
    "    # Set attributes on nodes\n",
    "    nx.set_node_attributes(G, identifier, name='id')\n",
    "    nx.set_node_attributes(G, labels, name='label')\n",
    "    nx.set_node_attributes(G, node_action_systems_id, name='actionSystemId')\n",
    "    nx.set_node_attributes(G, node_action_systems, name='actionSystem')\n",
    "    nx.set_node_attributes(G, influences, name='influence')\n",
    "    \n",
    "    return G\n",
    "\n",
    "def to_d3_json(G):\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    labels = nx.get_node_attributes(G, name='label')\n",
    "    influences = nx.get_node_attributes(G, name='influence')\n",
    "    action_systems = nx.get_node_attributes(G, name='actionSystem')\n",
    "    \n",
    "    weights = nx.get_edge_attributes(G, name='weight')\n",
    "    weight_absolute = nx.get_edge_attributes(G, name='weight_absolute')\n",
    "    strengthen = nx.get_edge_attributes(G, name='strengthen')\n",
    "    weaken = nx.get_edge_attributes(G, name='weaken')\n",
    "    sign = nx.get_edge_attributes(G, name='sign')\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        nodes.append({\n",
    "            'label': labels[i],\n",
    "            'influence': influences[i],\n",
    "            'actionSystem': action_systems[i]\n",
    "        })\n",
    "    \n",
    "    print(weights)\n",
    "    print(strengthen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric(graph, metric_name, metric_function, weights=[]):\n",
    "    \"\"\"Generate a Dictonary of all nodes/edges metrics returned by func\n",
    "    If weight list is provided a emtry will be generated for each weight\n",
    "\n",
    "    Keyword arguments:\n",
    "    graph -- the graph for which metrics should be generated\n",
    "    metric_name -- key in dictionary for this metric\n",
    "    metric_function -- function to calculate metric, func(G [, weight=weights])\n",
    "    weights -- list of weight attribute names in graph (default [])\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_data = {}\n",
    "    if len(weights) == 0:\n",
    "        # Metric is unweighted\n",
    "        metric_data[metric_name] = metric_function(graph)\n",
    "    else:\n",
    "        # Metric is weighted, go though every weight attribute\n",
    "        for i, weight in enumerate(weights):\n",
    "            metric_data['{}_{}'.format(metric_name, weight)] = metric_function(graph, weight=weight)\n",
    "            \n",
    "    return metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_metric(graph, weights=[]):\n",
    "    \"\"\"Generate a Dictonary of all nodes/edges metrics provided by networkx\n",
    "    If weight list is provided a emtry will be generated for each weight\n",
    "\n",
    "    Keyword arguments:\n",
    "    graph -- the graph for which metrics should be generated\n",
    "    weights -- list of weight attribute names in graph (default [])\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_data = {}\n",
    "    temp_data = {}\n",
    "    for i, weight in enumerate(weights):\n",
    "        temp_data['degree_{}'.format(weight)] = graph.degree(weight=weight)\n",
    "        temp_data['in_degree_{}'.format(weight)] = graph.in_degree(weight=weight)\n",
    "        temp_data['out_degree_{}'.format(weight)] = graph.out_degree(weight=weight)\n",
    "    \n",
    "    temp_data['degree'] = graph.degree()\n",
    "    temp_data['in_degree'] = graph.in_degree()\n",
    "    temp_data['out_degree'] = graph.out_degree()\n",
    "    \n",
    "    for i, metric in enumerate(temp_data):\n",
    "        metric_data[metric] = {}\n",
    "        for j, (node_id, value) in enumerate(temp_data[metric]):\n",
    "            metric_data[metric][node_id] = value\n",
    "    \n",
    "    return metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def graph_to_json(graph):\n",
    "    \"\"\"Generate a JSON formated string og the graph object with all possible\n",
    "    metrics provided by networkx\n",
    "\n",
    "    Keyword arguments:\n",
    "    graph -- the graph for which metrics should be generated\n",
    "    \"\"\"\n",
    "\n",
    "    json_object = {}\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    # If a key does not exist on access, generate empty list\n",
    "    # So every node gets a 'cycle' attribute, even if it's just an empty list\n",
    "    cycles = defaultdict(list)\n",
    "    \n",
    "    # Get attributes from nodes (generated by JSON importer)\n",
    "    identifier = nx.get_node_attributes(graph, name='id')\n",
    "    labels = nx.get_node_attributes(graph, name='label')\n",
    "    action_systems_id = nx.get_node_attributes(graph, name='actionSystemId')\n",
    "    action_systems = nx.get_node_attributes(graph, name='actionSystem')\n",
    "    influences = nx.get_node_attributes(graph, name='influence')\n",
    "    \n",
    "    # Get all possible directed graph metrics and add them to 'node_metrics' dict\n",
    "    node_metrics = {}\n",
    "    degree_metrics = rebuild_metric(graph, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(degree_metrics)\n",
    "    degree_centrality = generate_metric(graph, 'degree_centrality', nx.degree_centrality)\n",
    "    node_metrics.update(degree_centrality)\n",
    "    in_degree_centrality = generate_metric(graph, 'in_degree_centrality', nx.in_degree_centrality)\n",
    "    node_metrics.update(in_degree_centrality)\n",
    "    out_degree_centrality = generate_metric(graph, 'out_degree_centrality', nx.out_degree_centrality)\n",
    "    node_metrics.update(out_degree_centrality)\n",
    "    eigenvector_centrality_numpy = generate_metric(graph, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy)\n",
    "    node_metrics.update(eigenvector_centrality_numpy)\n",
    "    eigenvector_centrality_numpy_weighted = generate_metric(graph, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(eigenvector_centrality_numpy_weighted)\n",
    "    closeness_centrality = generate_metric(graph, 'closeness_centrality', nx.degree_centrality)\n",
    "    node_metrics.update(closeness_centrality)\n",
    "    betweenness_centrality = generate_metric(graph, 'betweenness_centrality', nx.betweenness_centrality)\n",
    "    node_metrics.update(betweenness_centrality)\n",
    "    betweenness_centrality_weighted = generate_metric(graph, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(betweenness_centrality_weighted)\n",
    "    load_centrality = generate_metric(graph, 'load_centrality', nx.load_centrality)\n",
    "    node_metrics.update(load_centrality)\n",
    "    load_centrality_weighted = generate_metric(graph, 'load_centralityload_centrality', nx.load_centrality, ['weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(load_centrality_weighted)\n",
    "    harmonic_centrality = generate_metric(graph, 'harmonic_centrality', nx.harmonic_centrality)\n",
    "    node_metrics.update(harmonic_centrality)\n",
    "    betweenness_centrality_weighted = generate_metric(graph, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "    node_metrics.update(betweenness_centrality_weighted)\n",
    "    \n",
    "    node_metrics_list = sorted(list(node_metrics.keys()))\n",
    "    \n",
    "    # Find cycles and build a 'cycle id' list\n",
    "    # Nodes with the same 'cycle id' belong to the same cycle\n",
    "    for i, cycle in enumerate(list(nx.simple_cycles(graph))):\n",
    "        for j, node in enumerate(cycle):\n",
    "            cycles[node].append(i)\n",
    "            \n",
    "    # Generate sorted int list of 'cycle id'\n",
    "    cycles_list = [int(i) for i in sorted(list(cycles.keys()))]\n",
    "    \n",
    "    # Fill 'nodes' dict\n",
    "    for i in range(len(identifier)):\n",
    "        attributes = {\n",
    "            'id': identifier[i],\n",
    "            'label': labels[i],\n",
    "            'influence': influences[i],\n",
    "            'actionSystemId': action_systems_id[i],\n",
    "            'actionSystem': action_systems[i],\n",
    "            'cycles': cycles[i]\n",
    "        }\n",
    "        \n",
    "        for k, metric in enumerate(node_metrics):\n",
    "            attributes[metric] = node_metrics[metric][i]\n",
    "        \n",
    "        nodes.append(attributes)\n",
    "\n",
    "    # Get attributes from edges (generated by JSON importer)\n",
    "    weight_absolute = nx.get_edge_attributes(graph, name='weight_absolute')\n",
    "    strengthen = nx.get_edge_attributes(graph, name='strengthen')\n",
    "    weaken = nx.get_edge_attributes(graph, name='weaken')\n",
    "    sign = nx.get_edge_attributes(graph, name='sign')\n",
    "    \n",
    "    # Get all possible directed graph metrics and add them to 'edge_metrics' dict\n",
    "    edge_metrics = {}\n",
    "    edge_betweenness_centrality = generate_metric(graph, 'edge_betweenness_centrality', nx.edge_betweenness_centrality)\n",
    "    edge_metrics.update(edge_betweenness_centrality)\n",
    "    edge_betweenness_centrality_weighted = generate_metric(graph, 'edge_betweenness_centrality', nx.edge_betweenness_centrality, weights=['weight','weight_absolute','strengthen','weaken'])\n",
    "    edge_metrics.update(edge_betweenness_centrality_weighted)\n",
    "    edge_load_centrality = generate_metric(graph, 'edge_load_centrality', nx.edge_load_centrality)\n",
    "    edge_metrics.update(edge_load_centrality)\n",
    "    \n",
    "    edge_metrics_list = sorted(list(edge_metrics.keys()))\n",
    "    \n",
    "    # Fill 'links' dict\n",
    "    for (from_node, to_node, weight) in graph.edges(data='weight'):\n",
    "        attributes = {\n",
    "            'source': nodes[from_node]['id'],\n",
    "            'target': nodes[to_node]['id'],\n",
    "            'weight': weight,\n",
    "            'weight_absolute': weight_absolute[(from_node, to_node, 0)],\n",
    "            'strengthen': strengthen[(from_node, to_node, 0)],\n",
    "            'weaken': weaken[(from_node, to_node, 0)],\n",
    "            'sign': sign[(from_node, to_node, 0)]\n",
    "        }\n",
    "        \n",
    "        for k, metric in enumerate(edge_metrics):\n",
    "            attributes[metric] = edge_metrics[metric][(from_node, to_node)]\n",
    "            \n",
    "        links.append(attributes)\n",
    "    \n",
    "    json_object['cycles'] = cycles_list\n",
    "    json_object['nodeProperties'] = node_metrics_list\n",
    "    json_object['edgeProperties'] = edge_metrics_list\n",
    "    json_object['nodes'] = nodes\n",
    "    json_object['links'] = links\n",
    "    \n",
    "    return json.JSONEncoder(ensure_ascii=False, allow_nan=False).encode(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_json_file(graph, filename):\n",
    "    \"\"\"Generate a JSON formated file.\n",
    "\n",
    "    Keyword arguments:\n",
    "    graph -- the graph for which a file should be generated\n",
    "    filename -- path and filename where to save the file \n",
    "    \"\"\"\n",
    "    \n",
    "    file = codecs.open(filename, \"w\", \"utf-8-sig\")\n",
    "    file.write(graph_to_json(graph))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"json-test.json\"\n",
    "\n",
    "def on_value_change(change):\n",
    "    G = json_to_graph(change['new'])\n",
    "    graph_to_json_file(G, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_file_picker(data_path, output_file):\n",
    "    output_file = output_file\n",
    "    files = {}\n",
    "\n",
    "    for file in enumerate(os.listdir(data_path)):\n",
    "        files[file[1]] = '{}{}'.format(data_path, file[1])\n",
    "        \n",
    "    filePicker = widgets.Dropdown(\n",
    "        options=files,\n",
    "        layout=Layout(width='100%'),\n",
    "        description='File:',\n",
    "    )\n",
    "\n",
    "    display(filePicker)\n",
    "\n",
    "    filePicker.observe(on_value_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
