{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Json2Graph import json_to_graph\n",
    "from DrawGraph import draw_nodes, draw_edges, draw_labels, draw_graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = json_to_graph('data/dataset_20180403/180402_Lukas_Herkunfts-_Pflegefamilie_Schule.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted Degree:')\n",
    "print(G.degree(weight='weight'))\n",
    "print('Positive Weighted Degree:')\n",
    "print(G.degree(weight='strengthen'))\n",
    "print('Negative Weighted Degree:')\n",
    "print(G.degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.degree(weight='weight_absolute'))\n",
    "print('Degree:')\n",
    "print(G.degree())\n",
    "print('Weighted In-Degree:')\n",
    "print(G.in_degree(weight='weight'))\n",
    "print('Positive Weighted In-Degree:')\n",
    "print(G.in_degree(weight='strengthen'))\n",
    "print('Negative Weighted In-Degree:')\n",
    "print(G.in_degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.in_degree(weight='weight_absolute'))\n",
    "print('In-Degree:')\n",
    "print(G.in_degree())\n",
    "print('Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='weight'))\n",
    "print('Positive Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='strengthen'))\n",
    "print('Negative Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.out_degree(weight='weight_absolute'))\n",
    "print('Out-Degree:')\n",
    "print(G.out_degree(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = -2\n",
    "print(abs(w) if np.sign(w) == 1 else 0)\n",
    "print(abs(w) if np.sign(w) == -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, nbrsdict in G.adjacency():\n",
    "    for nbr, keydict in nbrsdict.items():\n",
    "        for key, eattr in keydict.items():\n",
    "            print(eattr)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import approximation as ap\n",
    "print('Approximation:')\n",
    "print('all_pairs_node_connectivity:')\n",
    "apc = ap.all_pairs_node_connectivity(G)\n",
    "for key, value in apc.items():\n",
    "    print('{}: {}'.format(key, value))\n",
    "print('node_connectivity: {}'.format(ap.node_connectivity(G)))\n",
    "#ap.k_components(G) - only undirected\n",
    "print('max_clique: {}'.format(ap.max_clique(G)))\n",
    "#ap.average_clustering(G) - only undirected\n",
    "#ap.min_weighted_dominating_set(G, weight='weight') - only undirected\n",
    "print('maximum_independent_set: {}'.format(ap.maximum_independent_set(G)))\n",
    "print('min_maximal_matching: {}'.format(ap.min_maximal_matching(G)))\n",
    "print('ramsey_R2: {}'.format(ap.ramsey_R2(G)))\n",
    "#ap.metric_closure(G, weight='weight') - only undirected\n",
    "print('min_weighted_vertex_cover: {}'.format(ap.min_weighted_vertex_cover(G, weight='weight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community as co\n",
    "import itertools\n",
    "\n",
    "k = 20\n",
    "comp = co.girvan_newman(G)\n",
    "for communities in itertools.islice(comp, k):\n",
    "    print(tuple(sorted(c) for c in communities)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_to_dataframe(df, name, func, weights=[]):\n",
    "    if len(weights) == 0:\n",
    "        data = func(G)\n",
    "        kwargs = {name : list(data.values())}\n",
    "        df = df.assign(**kwargs)\n",
    "    else:\n",
    "        for i, weight in enumerate(weights):\n",
    "            data = func(G, weight=weight)\n",
    "            kwargs = {'{} - {}'.format(name, weight) : list(data.values())}\n",
    "            df = df.assign(**kwargs)\n",
    "    return df\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df = add_to_dataframe(df, 'degree_centrality', nx.degree_centrality)\n",
    "df = add_to_dataframe(df, 'in_degree_centrality', nx.in_degree_centrality)\n",
    "df = add_to_dataframe(df, 'out_degree_centrality', nx.out_degree_centrality)\n",
    "df = add_to_dataframe(df, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy)\n",
    "df = add_to_dataframe(df, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy, ['weight','weight_absolute','strengthen','weaken'])\n",
    "df = add_to_dataframe(df, 'closeness_centrality', nx.degree_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'edge_betweenness_centrality', nx.edge_betweenness_centrality)\n",
    "#df = add_to_dataframe(df, 'edge_betweenness_centrality', nx.edge_betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'approximate_current_flow_betweenness_centrality', nx.approximate_current_flow_betweenness_centrality)\n",
    "#df = add_to_dataframe(df, 'approximate_current_flow_betweenness_centrality', nx.approximate_current_flow_betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "df = add_to_dataframe(df, 'load_centrality', nx.load_centrality)\n",
    "df = add_to_dataframe(df, 'load_centrality', nx.load_centrality, ['weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'edge_load_centrality', nx.edge_load_centrality)\n",
    "df = add_to_dataframe(df, 'harmonic_centrality', nx.harmonic_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "\n",
    "\n",
    "print('edge_betweenness_centrality: {}'.format(nx.edge_betweenness_centrality(G)))\n",
    "print('edge_betweenness_centrality (weighted): {}'.format(nx.edge_betweenness_centrality(G, weight='weight')))\n",
    "print('approximate_current_flow_betweenness_centrality: {}'.format(nx.edge_betweenness_centrality(G)))\n",
    "print('approximate_current_flow_betweenness_centrality (weighted): {}'.format(nx.edge_betweenness_centrality(G, weight='weight')))\n",
    "print('edge_load_centrality: {}'.format(nx.load_centrality(G)))\n",
    "print('global_reaching_centrality: {}'.format(nx.global_reaching_centrality(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_network(G, alpha=1.):\n",
    "    local_g = G.copy()\n",
    "    egde_traversal = list(nx.edge_dfs(local_g))\n",
    "    influence = nx.get_node_attributes(local_g, 'influence')\n",
    "    weight_absolute = nx.get_edge_attributes(local_g, 'weight_absolute')\n",
    "    \n",
    "    for i, (from_node, to_node, node_key) in enumerate(egde_traversal):\n",
    "#         print('traveling from {} to {}'.format(from_node, to_node))\n",
    "#         print('influence of {} before: {}'.format(to_node, influence[to_node]))\n",
    "#         print('influence[from_node]: {}'.format(influence[from_node]))\n",
    "#         print('influence[to_node]: {}'.format(influence[to_node]))\n",
    "        computed_influence = influence[to_node] + (influence[from_node] * (alpha * weight_absolute[(from_node, to_node, 0)]))\n",
    "#         print('computed_influence: {}'.format(computed_influence))\n",
    "        if influence[to_node] == 0:\n",
    "            influence[to_node] = 0\n",
    "        elif np.sign(influence[to_node]) == 1:\n",
    "            influence[to_node] = computed_influence if computed_influence > 0 else 0\n",
    "        else:\n",
    "            influence[to_node] = computed_influence if computed_influence < 0 else 0\n",
    "        print('influence of {} after: {}'.format(to_node, influence[to_node]))\n",
    "#         print()\n",
    "        \n",
    "    nx.set_node_attributes(local_g, influence,'influence')\n",
    "    \n",
    "    return local_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daG = amplify_network(G, alpha=0.05)\n",
    "print()\n",
    "for i in range(10):\n",
    "    daG = amplify_network(daG, alpha=0.05)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def graph_to_json(G):\n",
    "    json_object = {}\n",
    "    nodes = []\n",
    "    links = []\n",
    "    \n",
    "    cycles = defaultdict(list)\n",
    "    \n",
    "    identifier = nx.get_node_attributes(G, name='id')\n",
    "    labels = nx.get_node_attributes(G, name='label')\n",
    "    action_systems_id = nx.get_node_attributes(G, name='actionSystemId')\n",
    "    action_systems = nx.get_node_attributes(G, name='actionSystem')\n",
    "    influences = nx.get_node_attributes(G, name='influence')\n",
    "    \n",
    "    for i, cycle in enumerate(list(nx.simple_cycles(G))):\n",
    "        for j, node in enumerate(cycle):\n",
    "            cycles[node].append(i)\n",
    "\n",
    "    for i in range(len(identifier)):\n",
    "        nodes.append({\n",
    "            'id': identifier[i],\n",
    "            'label': labels[i],\n",
    "            'influence': influences[i],\n",
    "            'actionSystemId': action_systems_id[i],\n",
    "            'actionSystem': action_systems[i],\n",
    "            'cycles': cycles[i]\n",
    "        })\n",
    "\n",
    "    weight_absolute = nx.get_edge_attributes(G, name='weight_absolute')\n",
    "    strengthen = nx.get_edge_attributes(G, name='strengthen')\n",
    "    weaken = nx.get_edge_attributes(G, name='weaken')\n",
    "    sign = nx.get_edge_attributes(G, name='sign')\n",
    "    \n",
    "    \n",
    "    for (from_node, to_node, weight) in G.edges(data='weight'):\n",
    "        links.append({\n",
    "            'source': nodes[from_node]['id'],\n",
    "            'target': nodes[to_node]['id'],\n",
    "            'weight': weight,\n",
    "            'weight_absolute': weight_absolute[(from_node, to_node, 0)],\n",
    "            'strengthen': strengthen[(from_node, to_node, 0)],\n",
    "            'weaken': weaken[(from_node, to_node, 0)],\n",
    "            'sign': sign[(from_node, to_node, 0)]\n",
    "        })\n",
    "    \n",
    "    json_object['nodes'] = nodes\n",
    "    json_object['links'] = links\n",
    "    \n",
    "    return json.JSONEncoder(ensure_ascii=False, allow_nan=False).encode(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "file = codecs.open(\"json-test.json\", \"w\", \"utf-8-sig\")\n",
    "file.write(graph_to_json(G))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_to_json(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_edge_attributes(G, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pos = nx.circular_layout(G, scale=1)\n",
    "nx.draw(G, pos, font_size=12, with_labels=False, ax=ax)\n",
    "edgelabels = nx.get_edge_attributes(G, 'weight')\n",
    "edgelabels_2d = {}\n",
    "\n",
    "for (n1, n2, n3), label in edgelabels.items():\n",
    "    edgelabels_2d[(n1, n2)] = label\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edgelabels_2d)\n",
    "nodelabels = nx.draw_networkx_labels(G, pos, alpha=.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
