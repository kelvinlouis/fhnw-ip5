{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Json2Graph import draw_file_picker\n",
    "from DrawGraph import draw_nodes, draw_edges, draw_labels, draw_graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "from networkx.algorithms import community\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/dataset_20180403/'\n",
    "for file in os.listdir(path):\n",
    "    print(file)\n",
    "    file = codecs.open(filename, \"r\", \"utf-8-sig\")\n",
    "    import_json = file.read()\n",
    "    file.close()\n",
    "    print(time.ctime(os.path.getmtime('{}{}'.format(path,file))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = json_to_graph('data/dataset_20180403/180402_Lukas_Herkunfts-_Pflegefamilie_Schule.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted Degree:')\n",
    "print(G.degree(weight='weight'))\n",
    "print('Positive Weighted Degree:')\n",
    "print(G.degree(weight='strengthen'))\n",
    "print('Negative Weighted Degree:')\n",
    "print(G.degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.degree(weight='weight_absolute'))\n",
    "print('Degree:')\n",
    "print(G.degree())\n",
    "print('Weighted In-Degree:')\n",
    "print(G.in_degree(weight='weight'))\n",
    "print('Positive Weighted In-Degree:')\n",
    "print(G.in_degree(weight='strengthen'))\n",
    "print('Negative Weighted In-Degree:')\n",
    "print(G.in_degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.in_degree(weight='weight_absolute'))\n",
    "print('In-Degree:')\n",
    "print(G.in_degree())\n",
    "print('Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='weight'))\n",
    "print('Positive Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='strengthen'))\n",
    "print('Negative Weighted Out-Degree:')\n",
    "print(G.out_degree(weight='weaken'))\n",
    "print('Absolute Weighted Degree:')\n",
    "print(G.out_degree(weight='weight_absolute'))\n",
    "print('Out-Degree:')\n",
    "print(G.out_degree(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = -2\n",
    "print(abs(w) if np.sign(w) == 1 else 0)\n",
    "print(abs(w) if np.sign(w) == -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_edge_attributes(G):\n",
    "    all_attributes = []\n",
    "\n",
    "    for n, nbrsdict in G.adjacency():\n",
    "        for nbr, keydict in nbrsdict.items():\n",
    "            for key, eattr in keydict.items():\n",
    "                for attribute in eattr.keys():\n",
    "                    all_attributes.append(attribute)\n",
    "                pass\n",
    "\n",
    "    all_attributes = list(set(all_attributes))\n",
    "    \n",
    "    return all_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import approximation as ap\n",
    "print('Approximation:')\n",
    "print('all_pairs_node_connectivity:')\n",
    "apc = ap.all_pairs_node_connectivity(G)\n",
    "for key, value in apc.items():\n",
    "    print('{}: {}'.format(key, value))\n",
    "print('node_connectivity: {}'.format(ap.node_connectivity(G)))\n",
    "#ap.k_components(G) - only undirected\n",
    "print('max_clique: {}'.format(ap.max_clique(G)))\n",
    "#ap.average_clustering(G) - only undirected\n",
    "#ap.min_weighted_dominating_set(G, weight='weight') - only undirected\n",
    "print('maximum_independent_set: {}'.format(ap.maximum_independent_set(G)))\n",
    "print('min_maximal_matching: {}'.format(ap.min_maximal_matching(G)))\n",
    "print('ramsey_R2: {}'.format(ap.ramsey_R2(G)))\n",
    "#ap.metric_closure(G, weight='weight') - only undirected\n",
    "print('min_weighted_vertex_cover: {}'.format(ap.min_weighted_vertex_cover(G, weight='weight')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community as co\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "\n",
    "def heaviest(G):\n",
    "    u, v, w = max(G.edges(data='weight'), key=itemgetter(2))\n",
    "    return (u, v)\n",
    "\n",
    "k = 20\n",
    "comp = co.girvan_newman(G, most_valuable_edge=heaviest)\n",
    "for communities in itertools.islice(comp, k):\n",
    "    print(tuple(sorted(c) for c in communities)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_to_dataframe(df, name, func, weights=[]):\n",
    "    if len(weights) == 0:\n",
    "        data = func(G)\n",
    "        kwargs = {name : list(data.values())}\n",
    "        df = df.assign(**kwargs)\n",
    "    else:\n",
    "        for i, weight in enumerate(weights):\n",
    "            data = func(G, weight=weight)\n",
    "            kwargs = {'{} - {}'.format(name, weight) : list(data.values())}\n",
    "            df = df.assign(**kwargs)\n",
    "    return df\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df = add_to_dataframe(df, 'degree_centrality', nx.degree_centrality)\n",
    "df = add_to_dataframe(df, 'in_degree_centrality', nx.in_degree_centrality)\n",
    "df = add_to_dataframe(df, 'out_degree_centrality', nx.out_degree_centrality)\n",
    "df = add_to_dataframe(df, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy)\n",
    "df = add_to_dataframe(df, 'eigenvector_centrality_numpy', nx.eigenvector_centrality_numpy, ['weight','weight_absolute','strengthen','weaken'])\n",
    "df = add_to_dataframe(df, 'closeness_centrality', nx.degree_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'edge_betweenness_centrality', nx.edge_betweenness_centrality)\n",
    "#df = add_to_dataframe(df, 'edge_betweenness_centrality', nx.edge_betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'approximate_current_flow_betweenness_centrality', nx.approximate_current_flow_betweenness_centrality)\n",
    "#df = add_to_dataframe(df, 'approximate_current_flow_betweenness_centrality', nx.approximate_current_flow_betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "df = add_to_dataframe(df, 'load_centrality', nx.load_centrality)\n",
    "df = add_to_dataframe(df, 'load_centrality', nx.load_centrality, ['weight_absolute','strengthen','weaken'])\n",
    "#df = add_to_dataframe(df, 'edge_load_centrality', nx.edge_load_centrality)\n",
    "df = add_to_dataframe(df, 'harmonic_centrality', nx.harmonic_centrality)\n",
    "df = add_to_dataframe(df, 'betweenness_centrality', nx.betweenness_centrality, ['weight','weight_absolute','strengthen','weaken'])\n",
    "\n",
    "\n",
    "print('edge_betweenness_centrality: {}'.format(nx.edge_betweenness_centrality(G)))\n",
    "print('edge_betweenness_centrality (weighted): {}'.format(nx.edge_betweenness_centrality(G, weight='weight')))\n",
    "print('edge_load_centrality: {}'.format(nx.load_centrality(G)))\n",
    "print('global_reaching_centrality: {}'.format(nx.global_reaching_centrality(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_network(G, alpha=1.):\n",
    "    local_g = G.copy()\n",
    "    egde_traversal = list(nx.edge_dfs(local_g))\n",
    "    influence = nx.get_node_attributes(local_g, 'influence')\n",
    "    weight_absolute = nx.get_edge_attributes(local_g, 'weight_absolute')\n",
    "    \n",
    "    for i, (from_node, to_node, node_key) in enumerate(egde_traversal):\n",
    "#         print('traveling from {} to {}'.format(from_node, to_node))\n",
    "#         print('influence of {} before: {}'.format(to_node, influence[to_node]))\n",
    "#         print('influence[from_node]: {}'.format(influence[from_node]))\n",
    "#         print('influence[to_node]: {}'.format(influence[to_node]))\n",
    "        computed_influence = influence[to_node] + (influence[from_node] * (alpha * weight_absolute[(from_node, to_node, 0)]))\n",
    "#         print('computed_influence: {}'.format(computed_influence))\n",
    "        if influence[to_node] == 0:\n",
    "            influence[to_node] = 0\n",
    "        elif np.sign(influence[to_node]) == 1:\n",
    "            influence[to_node] = computed_influence if computed_influence > 0 else 0\n",
    "        else:\n",
    "            influence[to_node] = computed_influence if computed_influence < 0 else 0\n",
    "        print('influence of {} after: {}'.format(to_node, influence[to_node]))\n",
    "#         print()\n",
    "        \n",
    "    nx.set_node_attributes(local_g, influence,'influence')\n",
    "    \n",
    "    return local_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daG = amplify_network(G, alpha=0.05)\n",
    "print()\n",
    "for i in range(10):\n",
    "    daG = amplify_network(daG, alpha=0.05)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Json2Graph import draw_file_picker\n",
    "\n",
    "draw_file_picker(data_path='data/dataset_20180403/', output_file=\"json-test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
